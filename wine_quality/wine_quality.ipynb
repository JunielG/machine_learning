{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a184aae0-41e4-45a7-a75b-7ddc2e04ff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classifiers Models\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier,\n",
    "RandomForestClassifier, VotingClassifier, HistGradientBoostingClassifier, StackingClassifier)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE, RFECV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler ,OneHotEncoder, MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "# model_selection\n",
    "from sklearn.model_selection import (train_test_split, KFold, cross_val_score, GridSearchCV, StratifiedKFold, \n",
    "learning_curve, cross_val_predict, cross_validate, permutation_test_score, validation_curve, RandomizedSearchCV)\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (accuracy_score, cohen_kappa_score, confusion_matrix, mean_squared_error, r2_score,\n",
    "root_mean_squared_error, recall_score, roc_auc_score, roc_curve, mean_absolute_error, auc, classification_report, f1_score)\n",
    "\n",
    "# Display all columns\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e637abff-c54a-477f-af69-9b2917f64382",
   "metadata": {},
   "outputs": [],
   "source": [
    "cln = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides',\n",
    "       'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol',\n",
    "       'quality']\n",
    "\n",
    "red_wine = pd.read_csv('winequality-red.csv', names=cln, engine='pyarrow')\n",
    "white_wine = pd.read_csv('winequality-white.csv', names=cln, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542ffd35-3dc2-4f81-90c2-516b1aabc76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No missing values for red wine df:\n",
      "fixed_acidity           0\n",
      "volatile_acidity        0\n",
      "citric_acid             0\n",
      "residual_sugar          0\n",
      "chlorides               0\n",
      "free_sulfur_dioxide     0\n",
      "total_sulfur_dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n",
      "\n",
      "✅ No missing values for white wine df:\n",
      "fixed_acidity           0\n",
      "volatile_acidity        0\n",
      "citric_acid             0\n",
      "residual_sugar          0\n",
      "chlorides               0\n",
      "free_sulfur_dioxide     0\n",
      "total_sulfur_dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# missing values\n",
    "missing_values = red_wine.isna().sum()\n",
    "\n",
    "if len(missing_values) < 0:\n",
    "    print(\"❌ Missing data for following columns:\")\n",
    "else:\n",
    "    print(f\"✅ No missing values for red wine df:\\n{missing_values}\\n\")  \n",
    "\n",
    "# missing values\n",
    "missing_values = white_wine.isna().sum()\n",
    "\n",
    "if len(missing_values) < 0:\n",
    "    print(\"❌ Missing data for following columns:\")\n",
    "else:\n",
    "    print(f\"✅ No missing values for white wine df:\\n{missing_values}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e2a89a-4dea-4069-b90f-4acbd892ad2e",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1737a32d-c77d-4171-b111-ffd1a3211268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1599, 11)\n",
      "Feature names: Index(['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol'], dtype='object')\n",
      "Number of classes: 6\n",
      "Class distribution: [  0   0   0  10  53 681 638 199  18]\n",
      "\n",
      "X Train shape: (1279, 11)\n",
      "Y Train shape: (1279,)\n",
      "X Test shape: (320, 11)\n",
      "Y Test shape: (320,)\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "--- Basic Model Performance ---\n",
      "Accuracy test set: 0.5719\n",
      "Accuracy train set: 0.6122\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "--- Basic Model Performance Using Pipeline---\n",
      "Accuracy test set: 0.5750\n",
      "Accuracy train set: 0.6200\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 10 Most Important Features ---\n",
      "                      Coefficient\n",
      "volatile_acidity         1.124273\n",
      "density                  0.749768\n",
      "chlorides                0.738534\n",
      "pH                       0.652265\n",
      "free_sulfur_dioxide      0.361031\n",
      "fixed_acidity            0.325667\n",
      "citric_acid              0.145177\n",
      "residual_sugar          -0.185377\n",
      "sulphates               -0.651319\n",
      "total_sulfur_dioxide    -0.755071\n",
      "--- Bottom 10 Least Important Features ---\n",
      "                      Coefficient\n",
      "density                  0.749768\n",
      "chlorides                0.738534\n",
      "pH                       0.652265\n",
      "free_sulfur_dioxide      0.361031\n",
      "fixed_acidity            0.325667\n",
      "citric_acid              0.145177\n",
      "residual_sugar          -0.185377\n",
      "sulphates               -0.651319\n",
      "total_sulfur_dioxide    -0.755071\n",
      "alcohol                 -0.945667\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "--- Model With Hyperparameter Tuning ---\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 147\u001b[0m\n\u001b[1;32m    137\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m    138\u001b[0m     pipeline,\n\u001b[1;32m    139\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Fit grid search\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Best parameters and score\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the dataset (binary classification)\n",
    "# Prepare the data\n",
    "X = red_wine.drop(columns=['quality'], axis=1)\n",
    "y = red_wine['quality']\n",
    "\n",
    "# Print dataset information\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Feature names:\", X.columns)\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "print() \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X Train shape:\", X_train.shape)\n",
    "print(\"Y Train shape:\", y_train.shape)\n",
    "print(\"X Test shape:\",  X_test.shape)\n",
    "print(\"Y Test shape:\",  y_test.shape)\n",
    "print(\"-\" * 127) \n",
    "\n",
    "# Features and target names\n",
    "feature_names = X.columns\n",
    "target_names = y.values\n",
    "\n",
    "# Basic model with default parameters \n",
    "lr = LogisticRegression(max_iter=100000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_train_lr = lr.predict(X_train)\n",
    "\n",
    "# Evaluate the basic model\n",
    "print(\"--- Basic Model Performance ---\")\n",
    "print(f\"Accuracy test set: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Accuracy train set: {accuracy_score(y_train, y_pred_train_lr):.4f}\")\n",
    "print('-' *127)  \n",
    "\n",
    "# Feature importance\n",
    "basic_model = lr.coef_\n",
    "if hasattr(basic_model, 'coef_'):\n",
    "    # Get feature importances (coefficients)\n",
    "    importances = pd.DataFrame(\n",
    "        basic_model.coef_[0],\n",
    "        index=X_train.columns,\n",
    "        columns=['Coefficient']\n",
    "    ).sort_values('Coefficient', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    top_features = importances.head(15)\n",
    "    top_features['Coefficient'].plot(kind='barh', color='teal')\n",
    "    plt.title('Top 15 Feature Importances Of Basic Model')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('feature_importance.png')\n",
    "    #plt.close()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"--- Top 10 Most Important Features ---\")\n",
    "    print(importances.head(10))\n",
    "    print(\"--- Bottom 10 Least Important Features ---\")\n",
    "    print(importances.tail(10))\n",
    "    print('-' *127)  \n",
    "    \n",
    "# Basic model with default parameters using pipeline\n",
    "# Create a pipeline with preprocessing and logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scale features\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=100000))  # Logistic regression model\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "y_pred_pipe_train = pipeline.predict(X_train)\n",
    "\n",
    "# Evaluate the basic model\n",
    "print(\"--- Basic Model Performance Using Pipeline---\")\n",
    "print(f\"Accuracy test set: {accuracy_score(y_test, y_pred_pipe):.4f}\")\n",
    "print(f\"Accuracy train set: {accuracy_score(y_train, y_pred_pipe_train):.4f}\") \n",
    "print('-' *127)   \n",
    "\n",
    "# Feature importance\n",
    "pipeline_model = pipeline.named_steps['classifier']\n",
    "if hasattr(pipeline_model, 'coef_'):\n",
    "    # Get feature importances (coefficients)\n",
    "    importances = pd.DataFrame(\n",
    "        pipeline_model.coef_[0],\n",
    "        index=X_train.columns,\n",
    "        columns=['Coefficient']\n",
    "    ).sort_values('Coefficient', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    top_features = importances.head(15)\n",
    "    top_features['Coefficient'].plot(kind='barh', color='teal')\n",
    "    plt.title('Top 15 Feature Importances')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('feature_importance.png')\n",
    "    #plt.close()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"--- Top 10 Most Important Features ---\")\n",
    "    print(importances.head(10))\n",
    "    print(\"--- Bottom 10 Least Important Features ---\")\n",
    "    print(importances.tail(10))\n",
    "    print('-' *127)  \n",
    "    \n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "print(\"--- Model With Hyperparameter Tuning ---\")\n",
    "param_grid = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'classifier__penalty': ['l1', 'l2'],  # Regularization type\n",
    "    'classifier__solver': ['liblinear', 'saga'],  # Algorithm to use\n",
    "    'classifier__max_iter': [100000, 1000000, 10000000],  # Max iterations\n",
    "    'classifier__class_weight': [None, 'balanced']  # Class weighting\n",
    "}\n",
    "\n",
    "# Create grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
    "print('-' *127)  \n",
    "\n",
    "# Evaluate the tuned model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "y_pred_tuned_train = best_model.predict(X_train)\n",
    "y_prob_tuned = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"--- Tuned Model Performance ---\")\n",
    "print(f\"Accuracy Tuned Test: {accuracy_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"Accuracy Tuned Train: {accuracy_score(y_train, y_pred_tuned_train):.4f}\")\n",
    "print('-' *127)   \n",
    "\n",
    "# Compare basic and tuned models\n",
    "print(\"--- Model Comparison ---\")\n",
    "print(f\"Basic Model Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Grid Tuned Model Accuracy: {accuracy_score(y_test, y_pred_tuned):.4f}\")\n",
    "print(f\"Pipeline Model Accuracy: {accuracy_score(y_test, y_pred_pipe):.4f}\")\n",
    "print('-' *127) \n",
    "\n",
    "# Calculate cross-validation scores for both models\n",
    "cv_scores_basic = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "cv_scores_tuned = cross_val_score(best_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Basic Model Cross-Validation Scores: {cv_scores_basic}\")\n",
    "print(f\"Tuned Model Cross-Validation Scores: {cv_scores_tuned}\\n\")\n",
    "print(f\"Basic Model Average CV Score: {cv_scores_basic.mean():.4f} ± {cv_scores_basic.std():.4f}\")\n",
    "print(f\"Tuned Model Average CV Score: {cv_scores_tuned.mean():.4f} ± {cv_scores_tuned.std():.4f}\") \n",
    "print('-' *127)   \n",
    "\n",
    "# Feature importance\n",
    "final_model = best_model.named_steps['classifier']\n",
    "if hasattr(final_model, 'coef_'):\n",
    "    # Get feature importances (coefficients)\n",
    "    importances = pd.DataFrame(\n",
    "        final_model.coef_[0],\n",
    "        index=X_train.columns,\n",
    "        columns=['Coefficient']\n",
    "    ).sort_values('Coefficient', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    top_features = importances.head(15)\n",
    "    top_features['Coefficient'].plot(kind='barh', color='teal')\n",
    "    plt.title('Top 15 Feature Importances')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('feature_importance.png')\n",
    "    #plt.close()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"--- Top 10 Most Important Features ---\")\n",
    "    print(importances.head(10))\n",
    "    print(\"--- Bottom 10 Least Important Features ---\")\n",
    "    print(importances.tail(10))\n",
    "    print('-' *127)   \n",
    "    \n",
    "# Learning curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_model, X, y, cv=5, n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', marker='s', markersize=5, label='Validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.15, color='green')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('learning_curve.png')\n",
    "#plt.close()\n",
    "plt.show()\n",
    "\n",
    "# Dataframe Predicted\n",
    "base_model_df = pd.DataFrame(X_test)\n",
    "base_model_df['prediction'] = np.round(y_pred_lr, 3)\n",
    "display(base_model_df.head())\n",
    "\n",
    "grid_model_df = pd.DataFrame(X_test)\n",
    "grid_model_df['prediction'] = np.round(y_pred_tuned, 3)\n",
    "display(grid_model_df.head())\n",
    "\n",
    "pipe_model_df = pd.DataFrame(X_test)\n",
    "pipe_model_df['prediction'] = np.round(y_pred_pipe, 3)\n",
    "display(pipe_model_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6051e465-72f9-4fb4-bd58-811066eedce6",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72885ffc-e136-4a6c-b4f0-78e5a5345f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Various Classes\n",
    "# Prepare the data\n",
    "X = red_wine.drop(columns=['quality'], axis=1)\n",
    "y = red_wine['quality']\n",
    "\n",
    "# Print dataset information\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Feature names:\", X.columns)\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "print() \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X Train shape:\", X_train.shape)\n",
    "print(\"Y Train shape:\", y_train.shape)\n",
    "print(\"X Test shape:\",  X_test.shape)\n",
    "print(\"Y Test shape:\",  y_test.shape)\n",
    "print(\"-\" * 127) \n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Basic AdaBoost model with default parameters\n",
    "print(\"--- Basic AdaBoost Model ---\")\n",
    "base_model = AdaBoostClassifier(random_state=42)\n",
    "base_model.fit(X_train_scaled, y_train)\n",
    "y_pred = base_model.predict(X_test_scaled)\n",
    "y_pred_train = base_model.predict(X_train_scaled)\n",
    "\n",
    "print(f\"Accuracy test set: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Accuracy train set: {accuracy_score(y_train, y_pred_train):.4f}\")\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "print(\"\\n--- Grid Search for Hyperparameter Tuning ---\")\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'estimator__max_depth': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Create base estimator\n",
    "base_estimator = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create AdaBoost model\n",
    "adaboost = AdaBoostClassifier(estimator=base_estimator, random_state=42)\n",
    "\n",
    "# Create grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=adaboost,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\\n\")\n",
    "\n",
    "# Train model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_grid = best_model.predict(X_test_scaled)\n",
    "y_pred_grid_train = best_model.predict(X_train_scaled)\n",
    "print(f\"Test accuracy with best model test set: {accuracy_score(y_test, y_pred_grid):.4f}\")\n",
    "print(f\"Test accuracy with best model train set: {accuracy_score(y_train, y_pred_grid_train):.4f}\")\n",
    "\n",
    "# Visualize feature importances\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    # For AdaBoost, feature_importances_ is available after fitting\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    else:\n",
    "        # For pipeline, need to access the classifier\n",
    "        importances = model.named_steps['adaboost'].feature_importances_\n",
    "    \n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.bar(range(len(indices[:15])), importances[indices[:15]], align='center')\n",
    "    plt.xticks(range(len(indices[:15])), [feature_names[i] for i in indices[:15]], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Feature Importances ---\")\n",
    "plot_feature_importance(best_model, X_train.columns)\n",
    "\n",
    "# Learning curve\n",
    "def plot_learning_curve(estimator, X, y, title=\"Learning Curve\", ylim=None, cv=5, n_jobs=-1):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, \n",
    "        train_sizes=np.linspace(.1, 1.0, 5))\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Learning Curve ---\")\n",
    "plot_learning_curve(best_model, X_train_scaled, y_train)\n",
    "\n",
    "# Effect of different learning rates\n",
    "def plot_learning_rate_effect():\n",
    "    learning_rates = [0.01, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        model = AdaBoostClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=3),\n",
    "            n_estimators=100,\n",
    "            learning_rate=lr,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        train_scores.append(accuracy_score(y_train, model.predict(X_train_scaled)))\n",
    "        test_scores.append(accuracy_score(y_test, model.predict(X_test_scaled)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(learning_rates, train_scores, 'o-', color='r', label='Training Accuracy')\n",
    "    plt.plot(learning_rates, test_scores, 'o-', color='g', label='Test Accuracy')\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Effect of Learning Rate on AdaBoost Performance')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Effect of Learning Rate ---\")\n",
    "plot_learning_rate_effect()\n",
    "\n",
    "# Effect of number of estimators\n",
    "def plot_n_estimators_effect():\n",
    "    n_estimators_range = [10, 50, 100, 200, 300, 400, 500]\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for n_est in n_estimators_range:\n",
    "        model = AdaBoostClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=3),\n",
    "            n_estimators=n_est,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        train_scores.append(accuracy_score(y_train, model.predict(X_train_scaled)))\n",
    "        test_scores.append(accuracy_score(y_test, model.predict(X_test_scaled)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(n_estimators_range, train_scores, 'o-', color='r', label='Training Accuracy')\n",
    "    plt.plot(n_estimators_range, test_scores, 'o-', color='g', label='Test Accuracy')\n",
    "    plt.xlabel('Number of Estimators')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Effect of Number of Estimators on AdaBoost Performance')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Effect of Number of Estimators ---\")\n",
    "plot_n_estimators_effect()\n",
    "\n",
    "# Pipeline example with AdaBoost\n",
    "print(\"\\n--- Pipeline with AdaBoost ---\")\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('adaboost', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameters for pipeline\n",
    "pipeline_params = {\n",
    "    'adaboost__estimator': [DecisionTreeClassifier(max_depth=1, random_state=42),\n",
    "                           DecisionTreeClassifier(max_depth=3, random_state=42)],\n",
    "    'adaboost__n_estimators': [50, 100, 200],\n",
    "    'adaboost__learning_rate': [0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Randomized search to speed up the tuning process\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=pipeline_params,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit randomized search\n",
    "random_search.fit(X_train, y_train)  # Note: Using unscaled data since scaling is part of the pipeline\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"Best pipeline parameters: {random_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {random_search.best_score_:.4f}\\n\")\n",
    "\n",
    "# Evaluate the best pipeline model\n",
    "best_pipeline = random_search.best_estimator_\n",
    "y_pred_pipeline = best_pipeline.predict(X_test)\n",
    "y_pred_pipeline_train = best_pipeline.predict(X_train)\n",
    "print(f\"Pipeline test accuracy:  {accuracy_score(y_test, y_pred_pipeline):.4f}\")\n",
    "print(f\"Pipeline train accuracy: {accuracy_score(y_train, y_pred_pipeline_train):.4f}\")\n",
    "\n",
    "# Compare with base model\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "print(f\"Base AdaBoost accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Grid Search tuned accuracy: {accuracy_score(y_test, y_pred_grid):.4f}\")\n",
    "print(f\"Pipeline tuned accuracy: {accuracy_score(y_test, y_pred_pipeline):.4f}\")\n",
    "\n",
    "# Dataframe Predicted\n",
    "base_model_df = pd.DataFrame(X_test)\n",
    "base_model_df['prediction'] = np.round(y_pred, 3)\n",
    "display(base_model_df.head())\n",
    "\n",
    "grid_model_df = pd.DataFrame(X_test)\n",
    "grid_model_df['prediction'] = np.round(y_pred_grid, 3)\n",
    "display(grid_model_df.head())\n",
    "\n",
    "pipe_model_df = pd.DataFrame(X_test)\n",
    "pipe_model_df['prediction'] = np.round(y_pred_pipeline, 3)\n",
    "display(pipe_model_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271f49b-3aa8-4156-ad76-3ec039a002eb",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325a528-d581-458a-b44b-6a20b777f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the dataset (binary classification)\n",
    "# Prepare the data\n",
    "X = df.drop(columns=['Class'], axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Print dataset information\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Feature names:\", X.columns)\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "print() \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X Train shape:\", X_train.shape)\n",
    "print(\"Y Train shape:\", y_train.shape)\n",
    "print(\"X Test shape:\",  X_test.shape)\n",
    "print(\"Y Test shape:\",  y_test.shape)\n",
    "print(\"-\" * 127) \n",
    "\n",
    "# Features and target names\n",
    "feature_names = X.columns\n",
    "target_names = y.values\n",
    "\n",
    "print(f\"Features: {len(feature_names)}\")\n",
    "print(f\"Classes: {target_names}\")\n",
    "print('-' *127)\n",
    "\n",
    "# Feature scaling (optional for RandomForest but good practice)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 1. Basic Random Forest model (baseline)\n",
    "rf_base = RandomForestClassifier(random_state=42)\n",
    "rf_base.fit(X_train_scaled, y_train)\n",
    "y_pred_base = rf_base.predict(X_test_scaled)\n",
    "y_pred_base_train = rf_base.predict(X_train_scaled)\n",
    "\n",
    "print(\"--- Baseline Random Forest Results ---\")\n",
    "print(f\"Accuracy Test Set: {accuracy_score(y_test, y_pred_base):.4f}\")\n",
    "print(f\"Accuracy Train Set: {accuracy_score(y_train, y_pred_base_train):.4f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importances = rf_base.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "plt.title('Baseline Random Forest Feature Importance')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('feature_importance.png')\n",
    "#plt.close()\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation of the best model\n",
    "cv_scores = cross_val_score(rf_base, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard deviation: {np.std(cv_scores):.4f}\")\n",
    "print('-' *100)  \n",
    "\n",
    "# 2. GridSearchCV for hyperparameter tuning\n",
    "print(\"--- Grid Search Hyperparameter Tuning ---\")\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Use smaller param_grid for demonstration purposes (to avoid long execution time)\n",
    "small_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=small_param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "plt.title('Grid Search Random Forest Feature Importance')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('feature_importance.png')\n",
    "#plt.close()\n",
    "plt.show() \n",
    "\n",
    "# Cross-validation of the best model\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard deviation: {np.std(cv_scores):.4f}\")\n",
    "print('-' *100)  \n",
    "\n",
    "# 3. RandomizedSearchCV (more efficient for large parameter spaces)\n",
    "print(\"--- Randomized Search Hyperparameter Tuning ---\")\n",
    "random_grid = {\n",
    "    'n_estimators': np.arange(100, 500, 100),\n",
    "    'max_depth': [None] + list(np.arange(10, 50, 10)),\n",
    "    'min_samples_split': np.arange(2, 12, 2),\n",
    "    'min_samples_leaf': np.arange(1, 5),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "randomized_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=20,  # Number of parameter settings sampled\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "randomized_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best parameters: {randomized_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {randomized_search.best_score_:.4f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importances = randomized_search.best_estimator_.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "plt.title('Randomized Search Random Forest Feature Importance')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('feature_importance.png')\n",
    "#plt.close()\n",
    "plt.show() \n",
    "\n",
    "# Cross-validation of the best model\n",
    "cv_scores = cross_val_score(randomized_search.best_estimator_, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard deviation: {np.std(cv_scores):.4f}\")\n",
    "print('-' *100) \n",
    "\n",
    "# 4. Evaluate the best model from GridSearchCV\n",
    "best_grid_model = grid_search.best_estimator_\n",
    "y_pred_grid = best_grid_model.predict(X_test_scaled)\n",
    "y_pred_grid_train = best_grid_model.predict(X_train_scaled)\n",
    "y_prob_grid = best_grid_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"--- Best Grid Search Model Evaluation ---\")\n",
    "print(f\"Accuracy Test Set: {accuracy_score(y_test, y_pred_grid):.4f}\")\n",
    "print(f\"Accuracy Train Set: {accuracy_score(y_train, y_pred_grid_train):.4f}\")\n",
    "print('-' *100) \n",
    "\n",
    "# 5. Feature importance analysis\n",
    "feature_importances = best_grid_model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "#plt.title('Random Forest Feature Importance')\n",
    "plt.title('Grid Search Random Forest Feature Importance')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('feature_importance.png')\n",
    "#plt.close()\n",
    "plt.show()\n",
    "\n",
    "# 6. Cross-validation of the best model\n",
    "cv_scores = cross_val_score(best_grid_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard deviation: {np.std(cv_scores):.4f}\")\n",
    "print('-' *100) \n",
    "\n",
    "# 7. Learning curves (optional for deeper analysis)\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_grid_model, X_train_scaled, y_train, cv=5, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy')\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', marker='s', markersize=5, label='Validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('learning_curve.png')\n",
    "#plt.close()\n",
    "plt.show()\n",
    "\n",
    "# 8. Fine-tuning specific parameters (optional based on previous findings)\n",
    "# For example, fine-tuning n_estimators after discovering optimal ranges\n",
    "print(\"--- Fine-tuning n_estimators ---\")\n",
    "estimator_range = np.arange(best_grid_model.n_estimators - 50, best_grid_model.n_estimators + 60, 10)\n",
    "estimator_range = estimator_range[estimator_range > 0]  # Ensure positive values\n",
    "\n",
    "param_grid_fine = {\n",
    "    'n_estimators': estimator_range\n",
    "}\n",
    "\n",
    "# Create a new RF with the best parameters from before\n",
    "rf_fine = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=best_grid_model.max_depth,\n",
    "    min_samples_split=best_grid_model.min_samples_split,\n",
    "    # Add other parameters from best_grid_model as needed\n",
    ")\n",
    "\n",
    "grid_search_fine = GridSearchCV(\n",
    "    estimator=rf_fine,\n",
    "    param_grid=param_grid_fine,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search_fine.fit(X_train_scaled, y_train)\n",
    "print(f\"Fine-tuned n_estimators: {grid_search_fine.best_params_['n_estimators']}\")\n",
    "print(f\"Fine-tuned accuracy: {grid_search_fine.best_score_:.4f}\")\n",
    "print('-' *100) \n",
    "\n",
    "# 9. Final model with all optimized parameters\n",
    "final_params = grid_search.best_params_.copy()\n",
    "final_params['n_estimators'] = grid_search_fine.best_params_['n_estimators']\n",
    "\n",
    "final_model = RandomForestClassifier(random_state=42, **final_params)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "y_pred_final = final_model.predict(X_test_scaled)\n",
    "y_pred_final_train = final_model.predict(X_train_scaled)\n",
    "\n",
    "print(\"--- Final Optimized Model Results ---\")\n",
    "print(f\"Final parameters RF: {final_params}\")\n",
    "print(f\"Accuracy Test Set: {accuracy_score(y_test, y_pred_final):.4f}\")\n",
    "print(f\"Accuracy Train Set: {accuracy_score(y_train, y_pred_final_train):.4f}\")\n",
    "\n",
    "# Compare with base model\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "print(f\"Base Random Forest accuracy: {accuracy_score(y_test, y_pred_base):.4f}\")\n",
    "print(f\"Grid Search tuned RF accuracy: {accuracy_score(y_test, y_pred_grid):.4f}\")\n",
    "print(f\"Final tuned RF accuracy: {accuracy_score(y_test, y_pred_final):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "236f9e60-3980-41ea-86d9-16e3921dd9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 4, 8, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine['quality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5baa6d15-6be6-4c33-b0f4-239d0a9e4e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  alcohol  quality\n",
       "0            7.4              0.70         0.00             1.9      0.076                 11.0                  34.0   0.9978  3.51       0.56      9.4        5\n",
       "1            7.8              0.88         0.00             2.6      0.098                 25.0                  67.0   0.9968  3.20       0.68      9.8        5\n",
       "2            7.8              0.76         0.04             2.3      0.092                 15.0                  54.0   0.9970  3.26       0.65      9.8        5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da4f0ae9-e24c-43f8-ac00-6c74c6e845cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 7, 8, 4, 3, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_wine['quality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd3e31c-867e-42cb-ba2c-692ce2a75a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  alcohol  quality\n",
       "0            7.0              0.27         0.36            20.7      0.045                 45.0                 170.0   1.0010  3.00       0.45      8.8        6\n",
       "1            6.3              0.30         0.34             1.6      0.049                 14.0                 132.0   0.9940  3.30       0.49      9.5        6\n",
       "2            8.1              0.28         0.40             6.9      0.050                 30.0                  97.0   0.9951  3.26       0.44     10.1        6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_wine.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828de0e8-61d8-4144-8344-4fb1d1b8c190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
